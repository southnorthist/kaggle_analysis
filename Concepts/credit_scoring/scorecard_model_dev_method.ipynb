{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Credit Scorecard Development Quick Start\n",
    "\n",
    "_First Version: 2022-12-15  \n",
    "Last Updates: 2022-12-16  \n",
    "Author: QH_\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. The development process\n",
    "Like any statistical model development, credit scorecard model development involves the same phases as follows if data sources have been identified and data has been collected by the developers:\n",
    "\n",
    "1. __Target Variable__\n",
    "    * Good/Bad binary target variable determination (TBA)\n",
    "    \n",
    "2. __Data Exploration__\n",
    "    * _Explore the distribution of each feature_\n",
    "        * Identify and deal with missing values:\n",
    "            * 1) Exclude the feature if missing percentage is $> 50\\%$.\n",
    "            * 2) Treat missing as a separate category - _Recommended_.   \n",
    "            Since from the credit risk perspective missing information is commonly associated with negative information on borrower's credit-worthiness. E.g. Borrowers may not want to provide current employee name or length of employment because they may be out of job market and in need of money to pay for bills. \n",
    "            * 3) Impute the values using mean, median or statistical methods.\n",
    "        * Identify and deal with outliers:\n",
    "            * Outliers may due to typing error or fraud. Investigation is often needed to proceed with treatment(remove or impute).\n",
    "    * _Initial univariate feature selection_\n",
    "        * Group all features into risk categories. For example for a business:\n",
    "            * Financial strength:\n",
    "                * Profitability: average profit margin, industry segment, average sales growth, etc.\n",
    "                * Liquidity: account balance, cash/assets, quick ratio, current ratio, etc.\n",
    "                * Indebtedness: debt to income ratio, debt service coverage ratio (DSCR)\n",
    "            * Credit History:\n",
    "                * previous credit payment behavior (e.g. number of times 30/60/90 days past due)\n",
    "                * business bureau score\n",
    "            * Business Stability: Years in the business, Management quality, ability to grow market share, average tenure of employees, turnover rate, etc.\n",
    "            * Geographic/Industry/Market impact: bankruptcy rate for the industry\n",
    "\n",
    "        * Rank predictive power for all features and make initial selection within each risk categories\n",
    "            * For credit scorecard models, sometimes we will use binning/grouping variables into categorical variables (e.g. to account for missing)\n",
    "                * Calculate the Weight of Evidence (WOE) measure for each feature.\n",
    "                * Calculate metrics to rank predictive power: Information Value (IV), Chi-square Test, Gini/AUC.\n",
    "                * Evaluate if the WOE is logical across all the bins and take business operation into consideration for feature selection.\n",
    "            * If we do not use binning/grouping, metrics to rank predictive power will be different for numeric and categorical as other classification problems:\n",
    "                * Categorical: _chi-square test statistics_ and _mutual information statistics_\n",
    "                * Numeric: _ANOVA f test statistics_ and _mutual information statistics_\n",
    "            \n",
    "    * _Multivariate variable selection_\n",
    "        * Remove features that is less predictive but has multi-colinearity with other features.\n",
    "\n",
    "3. Modeling\n",
    "    * We use WOE value from each bin to reprent the value of each bin from the selected features.\n",
    "    * Majority of the time, we use logistic regression for its advantage of simpliciy, interpretabilty and a lot of the times pretty good classification power.\n",
    "    * During the modeling process, we can use feature selection as well, e.g. forward selection or backward selection.\n",
    "        * To avoid the situation that some of the risk categories are being eliminated we can do the selection by risk categories.\n",
    "\n",
    "4. Scaling\n",
    "    * After classification has been done, we need to scale to generate a score to reflect borrowers' creditability. After specify 1) the odds (good to bad) at which score and 2) _points to double the odds (pdo)_, we can use the following relationship to scale up to obtain credit scores:\n",
    "    $$ \\text{Score} = \\text{Offset} + \\text{Factor} \\times \\log (\\text{odds})$$\n",
    "    $$\\text{Score} + pdo = \\text{Offset} + \\text{Factor} \\times \\log (2 \\cdot \\text{odds})$$\n",
    "    $$\\rightarrow \\text{Factor} = pdo / \\log(2), \\text{Offset} = \\text{Score} - (\\text{Factor} \\times \\log(\\text{Odds}))$$\n",
    "    * Example: If we want odds of good to bad 50:1 at 600 points and want the odds to double every 20 points, then\n",
    "    $$ \\text{Factor} = pdo / \\log(2) = 28.85,  \\text{Offset} = 600 - (28.85 \\times \\log(50)) = 487.12$$\n",
    "    * Since _Factor_ and _Offset_ has been determined, we can determine the credit score for each borrower using the fitted model:\n",
    "    $$\\begin{aligned}\n",
    "      \\text{Score} & = \\text{Offset} + \\text{Factor} \\times \\log(\\frac{1-\\hat{p}}{\\hat{p}}) \\\\\n",
    "                   &= \\text{Offset} + \\text{Factor} \\times \\bigg(- \\big(\\sum_{i=1} ^{M}\\beta_{i} \\sum_{j=1}^{K_i} I_{ij}\\times woe_{ij} + \\alpha \\big) \\bigg) \\\\\n",
    "                   &= \\sum_{i=1} ^{M} \\bigg(- \\text{Factor} \\times \\big( \\beta_{i} \\cdot \\sum_{j=1}^{K_i} I_{ij}\\times woe_{ij} + \\frac{\\alpha}{M}\\big)  + \\frac{\\text{offset}}{M}\\bigg) \\\\\n",
    "                   &= \\sum_{i=1} ^{M} \\bigg(- \\big(\\text{Factor} \\times \\beta_{i}\\big) \\cdot \\sum_{j=1}^{K_i} I_{ij}\\times woe_{ij} + \\frac{\\text{offset} - \\text{Factor} \\times \\alpha}{M}\\bigg)\n",
    "\n",
    "      \\end{aligned}\n",
    "    $$\n",
    "    where $M$ is the total number of features in the model, $K_i$ is the number of groups(bins) for the $i^{th}$ feature, $I_{ij}$ means when the $i^{th}$ feature value is in $j^{th}$ bin then value is 1 otherwise 0. From the last equation, we can calculate the score for each feature and add them together to be the final score."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Weight of Evidence (WOE) and Information Value (IV)\n",
    "\n",
    "Weight of Evidence (WOE) is the log odds of a borrower being good in that attribute/feature group and being bad in that attribute group. Mathematically, \n",
    "$$\n",
    "\\begin{aligned}\n",
    "woe_{ij} &= \\log \\bigg(\\frac{DistrGood_{ij}} {DistrBad_{ij}} \\bigg) = \\log \\bigg(\\frac{\\Pr(X_i \\in j|Good)}{\\Pr(X_i \\in j|Bad)} \\bigg) \\\\\n",
    "         &= \\log \\bigg( \\frac{\\Pr(X_i \\in j, Good) / \\Pr(Good)}{\\Pr(X_i \\in j, Bad) / \\Pr(Bad)}  \\bigg) \\\\\n",
    "         &= \\log \\bigg( \\frac{\\Pr(X_i \\in j, Good) / \\Pr(X_i \\in j, Bad)}{\\Pr(Good) / \\Pr(Bad)}  \\bigg)\n",
    "\\end{aligned}\n",
    "$$\n",
    "where $woe_{ij}$ means woe of $j^{th}$ group of feature $i$ .\n",
    "Information Value (IV) is the metric to evaluate the predictive power of the feature defined as follows:\n",
    "$$iv_{ij} =\\big( DistrGood_{ij} - DistrBad_{ij} \\big) \\cdot woe_{ij}$$\n",
    "$$\\rightarrow iv_{i} = \\sum_{j = 1}^{K_i} iv_{ij}$$\n",
    "Where $K_i$ is the number of groups(bins) for the $i^{th}$ feature.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information Value for the Feature is: 0.6680562518213035\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age_group</th>\n",
       "      <th>age_group_count</th>\n",
       "      <th>good_count</th>\n",
       "      <th>bad_count</th>\n",
       "      <th>event_distr</th>\n",
       "      <th>non_event_distr</th>\n",
       "      <th>woe</th>\n",
       "      <th>iv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Missing</td>\n",
       "      <td>1000</td>\n",
       "      <td>860</td>\n",
       "      <td>140</td>\n",
       "      <td>0.036458</td>\n",
       "      <td>0.023783</td>\n",
       "      <td>-0.427191</td>\n",
       "      <td>0.005415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18-22</td>\n",
       "      <td>4000</td>\n",
       "      <td>3040</td>\n",
       "      <td>960</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.084071</td>\n",
       "      <td>-1.089802</td>\n",
       "      <td>0.180830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23-26</td>\n",
       "      <td>6000</td>\n",
       "      <td>4920</td>\n",
       "      <td>1080</td>\n",
       "      <td>0.281250</td>\n",
       "      <td>0.136062</td>\n",
       "      <td>-0.726134</td>\n",
       "      <td>0.105426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27-29</td>\n",
       "      <td>9000</td>\n",
       "      <td>8100</td>\n",
       "      <td>900</td>\n",
       "      <td>0.234375</td>\n",
       "      <td>0.224004</td>\n",
       "      <td>-0.045257</td>\n",
       "      <td>0.000469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30-35</td>\n",
       "      <td>10000</td>\n",
       "      <td>9500</td>\n",
       "      <td>500</td>\n",
       "      <td>0.130208</td>\n",
       "      <td>0.262721</td>\n",
       "      <td>0.701958</td>\n",
       "      <td>0.093018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>35-44</td>\n",
       "      <td>7000</td>\n",
       "      <td>6800</td>\n",
       "      <td>200</td>\n",
       "      <td>0.052083</td>\n",
       "      <td>0.188053</td>\n",
       "      <td>1.283879</td>\n",
       "      <td>0.174569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>44+</td>\n",
       "      <td>3000</td>\n",
       "      <td>2940</td>\n",
       "      <td>60</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.081305</td>\n",
       "      <td>1.649339</td>\n",
       "      <td>0.108329</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  age_group  age_group_count  good_count  bad_count  event_distr  \\\n",
       "0   Missing             1000         860        140     0.036458   \n",
       "1     18-22             4000        3040        960     0.250000   \n",
       "2     23-26             6000        4920       1080     0.281250   \n",
       "3     27-29             9000        8100        900     0.234375   \n",
       "4     30-35            10000        9500        500     0.130208   \n",
       "5     35-44             7000        6800        200     0.052083   \n",
       "6       44+             3000        2940         60     0.015625   \n",
       "\n",
       "   non_event_distr       woe        iv  \n",
       "0         0.023783 -0.427191  0.005415  \n",
       "1         0.084071 -1.089802  0.180830  \n",
       "2         0.136062 -0.726134  0.105426  \n",
       "3         0.224004 -0.045257  0.000469  \n",
       "4         0.262721  0.701958  0.093018  \n",
       "5         0.188053  1.283879  0.174569  \n",
       "6         0.081305  1.649339  0.108329  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example of woe and iv - source from reference [1]\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "age_grp = ['Missing', '18-22', '23-26', '27-29', '30-35', '35-44', '44+']\n",
    "age_grp_count = [1000, 4000, 6000, 9000, 10000, 7000, 3000]\n",
    "good_count = [860, 3040, 4920, 8100, 9500, 6800, 2940]\n",
    "df = pd.DataFrame({'age_group': age_grp, 'age_group_count': age_grp_count, 'good_count': good_count})\n",
    "df['bad_count'] = df['age_group_count'] - df['good_count']\n",
    "\n",
    "def woe_iv_calc(df, event_cnt_var, non_event_cnt_var):\n",
    "    event_total = df[event_cnt_var].sum()\n",
    "    non_event_total = df[non_event_cnt_var].sum()\n",
    "    df['event_distr'] = df[event_cnt_var] / event_total\n",
    "    df['non_event_distr'] = df[non_event_cnt_var] / non_event_total\n",
    "    df['woe'] = np.log(df['non_event_distr'] / df['event_distr'])\n",
    "    df['iv'] = (df['non_event_distr'] - df['event_distr']) * df['woe']\n",
    "    print(f\"Information Value for the Feature is: {df['iv'].sum()}\")\n",
    "    return df\n",
    "\n",
    "woe_iv_calc(df, 'bad_count', 'good_count')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rule of thumb to determine a good predictive power using information value:\n",
    "* $IV < 0.02$: generally unpredictive\n",
    "* $0.02 \\leq IV \\le 0.1$: weak\n",
    "* $0.1 \\leq IV \\le 0.3$ medium\n",
    "* $IV \\geq 0.3$: strong"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference\n",
    "1. Intelligent Credit Scoring: Building and Implementing Better Credit Risk Scorecards, Second Edition"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4 (v3.9.4:1f2e3088f3, Apr  4 2021, 12:32:44) \n[Clang 6.0 (clang-600.0.57)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
